library(shiny)
library(shinydashboard)
library(readr)
library(dplyr)
library(ggplot2)
library(DT)
library(glue)
library(lubridate)
library(gdata)  # for gdata::humanReadable
library(magrittr)  # for extract2

library(promises)
library(future)
# Leave one core for Shiny itself
plan(multisession(workers = availableCores() - 1))

source("random-names.R")
source("modules/detail.R")

ui <- dashboardPage(
  dashboardHeader(
    title = "CRAN whales"
  ),
  dashboardSidebar(
    dateInput("date", "Date", value = Sys.Date() - 3),
    numericInput("count", "Show top N downloaders:", 6)
  ),
  dashboardBody(
    fluidRow(
      tabBox(width = 12,
        tabPanel("All traffic",
          fluidRow(
            valueBoxOutput("total_size", width = 4),
            valueBoxOutput("total_count", width = 4),
            valueBoxOutput("total_downloaders", width = 4)
          ),
          plotOutput("all_hour")
        ),
        tabPanel("Biggest whales",
          plotOutput("downloaders", height = 500)
        ),
        tabPanel("Whales by hour",
          plotOutput("downloaders_hour", height = 500)
        ),
        tabPanel("Detail view",
          detailViewUI("details")
        )
      )
    )
  )
)

server <- function(input, output, session) {
  
  ### Reactive expressions ============================================
  
  # Downloads data from cran-logs.rstudio.com, and parses it.
  # Successful downloads are stored in the data_cache dir.
  data <- eventReactive(input$date, ignoreNULL = FALSE, {
    date <- input$date
    validate(need(is.Date(date), "Invalid date"))
    
    year <- lubridate::year(date)
    
    url <- glue("http://cran-logs.rstudio.com/{year}/{date}.csv.gz")
    path <- file.path("data_cache", paste0(date, ".csv.gz"))
    
    p <- Progress$new()
    p$set(value = NULL, message = "Downloading data...")
    future({
      # Download to a temporary file path, then rename to the real
      # path when the download is complete. We do this so other
      # processes/sessions don't use partially downloaded files.
      if (!file.exists(path)) {
        tmppath <- paste0(path, "-", Sys.getpid())
        download.file(url, tmppath)
        if (!file.exists(path)) {
          file.rename(tmppath, path)
        } else {
          file.remove(tmppath)
        }
      }
    }) %...>%
      { p$set(message = "Parsing data...") } %...>%
      { future({
        df <- read_csv(path, col_types = "Dti---c-ci", progress = FALSE)
        whale_ip <- df %>%
          count(ip_id) %>%
          arrange(desc(n)) %>%
          head(25) %>%
          pull(ip_id)
        
        whale_data <- df %>% filter(ip_id %in% whale_ip)
        
        all_data <- df %>%
          mutate(
            time = hms::trunc_hms(time, 60*60),
            whale_class = match(ip_id, whale_ip)
          ) %>%
          count(time, whale_class)
        
        list(
          whale_data = whale_data,
          all_data = all_data,
          stats = list(
            total_size = sum(as.numeric(df$size)),
            total_count = nrow(df),
            total_uniques = length(unique(df$package)),
            total_downloaders = length(unique(df$ip_id))
          )
        )
        
      }) } %>%
      finally(~p$close())
  })
  
  # Returns a data frame of just the top `input$count` downloaders of the day,
  # with the columns: 
  # ip_id - an arbitrary integer that's used in place of the real IP address
  # ip_name - the same as ip_id but using easier-to-remember labels like
  #     "quant_weasel" or "nutritious_lovebird".
  # n - the number of downloads performed by this IP on this day
  whales <- reactive({
    validate(
      need(is.numeric(input$count), "Invalid top downloader count"),
      need(input$count > 0, "Too few downloaders"),
      need(input$count <= 25, "Too many downloaders; 25 or fewer please")
    )
    data() %...>%
      extract2("whale_data") %...>%
      count(ip_id, country) %...>%
      arrange(desc(n)) %...>%
      head(input$count) %...>%
      mutate(ip_name = factor(ip_id, levels = ip_id,
        labels = glue("{random_name(length(ip_id), input$date)} [{country}]"))) %...>%
      select(-country)
  })
  
  # data(), filtered down to the downloads that are by the top `input$count`
  # downloaders
  whale_downloads <- reactive({
    promise_all(data = data(), whales = whales()) %...>%
      with({
        data$whale_data %>%
          inner_join(whales, "ip_id") %>%
          select(-n)
      })
  })

  
  ### Outputs =========================================================
  
  #### "All traffic" tab ----------------------------------------
  
  output$total_size <- renderValueBox({
    data() %...>%
      extract2("stats") %...>%
      extract2("total_size") %...>%
      humanReadable() %...>%
      valueBox("bandwidth consumed")
  })
  
  output$total_count <- renderValueBox({
    data() %...>%
      extract2("stats") %...>%
      extract2("total_count") %...>%
      format(big.mark = ",") %...>%
      valueBox("files downloaded")
  })
  
  output$total_uniques <- renderValueBox({
    data() %...>%
      extract2("stats") %...>%
      extract2("total_uniques") %...>%
      format(big.mark = ",") %...>%
      valueBox("unique packages")
  })
  
  output$total_downloaders <- renderValueBox({
    data() %...>%
      extract2("stats") %...>%
      extract2("total_downloaders") %...>%
      format(big.mark = ",") %...>%
      valueBox("unique downloaders")
  })
  
  output$all_hour <- renderPlot({
    data() %...>%
      extract2("all_data") %...>%
      mutate(
        is_whale = !is.na(whale_class) & whale_class <= input$count
      ) %...>%
      group_by(time, is_whale) %...>%
      summarise(n = sum(n)) %...>%
      ungroup() %...>% {
        ggplot(., aes(time, n, fill = is_whale)) +
          geom_bar(stat = "identity") +
          scale_fill_manual(values = c("#666666", "#88FF99"),
            labels = c("no", "yes")) +
          ylab("Downloads") +
          xlab("Hour") +
          scale_y_continuous(labels = scales::comma)
      }
  })
  
  #### "Biggest whales" tab -------------------------------------
  
  output$downloaders <- renderPlot({
    whales() %...>% {
      ggplot(., aes(ip_name, n)) +
      geom_bar(stat = "identity") +
      ylab("Downloads on this day")
    }
  })
  
  #### "Whales by hour" tab -------------------------------------
  
  output$downloaders_hour <- renderPlot({
    whale_downloads() %...>%
      mutate(time = hms::trunc_hms(time, 60*60)) %...>%
      count(time, ip_name) %...>% {
        ggplot(., aes(time, n)) +
          geom_bar(stat = "identity") +
          facet_wrap(~ip_name) +
          ylab("Downloads") +
          xlab("Hour")
      }
  })
  
  #### "Detail view" tab ----------------------------------------

  callModule(detailView, "details", whales, whale_downloads)
}

shinyApp(ui, server)
